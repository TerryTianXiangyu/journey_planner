{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for getting connections dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'datavirus_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7478</td><td>application_1589299642358_1974</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1974/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1974_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7497</td><td>application_1589299642358_1992</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1992/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1992_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7509</td><td>application_1589299642358_2004</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2004/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2004_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7516</td><td>application_1589299642358_2011</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2011/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2011_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7518</td><td>application_1589299642358_2013</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2013/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2013_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7520</td><td>application_1589299642358_2015</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2015/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2015_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7522</td><td>application_1589299642358_2017</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2017/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2017_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7523</td><td>application_1589299642358_2018</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2018/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2018_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7524</td><td>application_1589299642358_2019</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2019/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2019_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>7525</td><td>application_1589299642358_2020</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2020/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2020_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"datavirus_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7526</td><td>application_1589299642358_2021</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2021/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2021_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f63747ff8d0>"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'datavirus_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6663</td><td>application_1589299642358_1152</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1152/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1152_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6668</td><td>application_1589299642358_1157</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1157/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1157_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6670</td><td>application_1589299642358_1159</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1159/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1159_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6671</td><td>application_1589299642358_1160</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1160/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1160_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6672</td><td>application_1589299642358_1161</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1161/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1161_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>6673</td><td>application_1589299642358_1162</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_1162/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_1162_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute probabilities and average delays using all possible data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load SBB data only for stations within 15 km of Zurich\n",
    "#ids_stations = spark.read.csv('../data/zurich_stations_ids.csv')\n",
    "#sbb_zurich = sbb.join(ids_stations,sbb['BPUIC']==ids_stations['_c0']).drop(\"_c0\")\n",
    "\n",
    "sbb = spark.read.orc('/data/sbb/orc/istdaten')\n",
    "sample = sbb.where(F.col('FAHRT_BEZEICHNER')=='85:11:17215:001')\\\n",
    "            .where((F.col('BETRIEBSTAG')=='13.05.2019') | (F.col('BETRIEBSTAG')=='14.05.2019') | (F.col('BETRIEBSTAG')=='15.05.2019') | (F.col('BETRIEBSTAG')=='16.05.2019'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_df = (\n",
    "    sample\n",
    "    .select('ankunftszeit','an_prognose','abfahrtszeit','BETRIEBSTAG','FAHRT_BEZEICHNER','LINIEN_ID','PRODUKT_ID','BPUIC','HALTESTELLEN_NAME')\n",
    "    .toDF('Arrival_Time','Arrival_Real','Departure_Time','Day','Trip_ID','Line_ID', 'Type','Station_ID', 'Station_Name')\n",
    "    .dropDuplicates()\n",
    "    .withColumn('arrival', F.unix_timestamp(F.col('Arrival_Time'), \"dd.MM.yyyy HH:mm\").cast('long'))\n",
    "    .withColumn('real_arrival', F.unix_timestamp(F.col('Arrival_Real'), \"dd.MM.yyyy HH:mm:ss\").cast(\"long\"))\n",
    "    .withColumn('Arrival_Delay',F.col('real_arrival')-F.col('arrival')).drop('arrival','real_arrival')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+---------------+-------+----+----------+--------------------+-------------+----------------+----------------+\n",
      "|       Arrival_Real|       Day|        Trip_ID|Line_ID|Type|Station_ID|        Station_Name|Arrival_Delay|       Departure|         Arrival|\n",
      "+-------------------+----------+---------------+-------+----+----------+--------------------+-------------+----------------+----------------+\n",
      "|                   |13.05.2019|85:11:17215:001|  17215| Zug|   8500010|           Basel SBB|         null|13.05.2019 04:59|13.05.2019 04:59|\n",
      "|13.05.2019 05:04:55|13.05.2019|85:11:17215:001|  17215| Zug|   8500020|             Muttenz|          115|13.05.2019 05:03|13.05.2019 05:03|\n",
      "|13.05.2019 05:08:38|13.05.2019|85:11:17215:001|  17215| Zug|   8500021|            Pratteln|           98|13.05.2019 05:07|13.05.2019 05:07|\n",
      "|13.05.2019 05:10:39|13.05.2019|85:11:17215:001|  17215| Zug|   8517131|Pratteln Salina R...|           99|13.05.2019 05:09|13.05.2019 05:09|\n",
      "|13.05.2019 05:12:52|13.05.2019|85:11:17215:001|  17215| Zug|   8500300|         Kaiseraugst|           52|13.05.2019 05:12|13.05.2019 05:12|\n",
      "|13.05.2019 05:15:46|13.05.2019|85:11:17215:001|  17215| Zug|   8500313|Rheinfelden Augarten|           46|13.05.2019 05:15|13.05.2019 05:15|\n",
      "|13.05.2019 05:18:09|13.05.2019|85:11:17215:001|  17215| Zug|   8500301|         Rheinfelden|            9|13.05.2019 05:18|13.05.2019 05:18|\n",
      "|13.05.2019 05:21:17|13.05.2019|85:11:17215:001|  17215| Zug|   8500302|              Möhlin|           17|13.05.2019 05:21|13.05.2019 05:21|\n",
      "|13.05.2019 05:26:04|13.05.2019|85:11:17215:001|  17215| Zug|   8500303|               Mumpf|           64|13.05.2019 05:25|13.05.2019 05:25|\n",
      "|13.05.2019 05:29:30|13.05.2019|85:11:17215:001|  17215| Zug|   8500320|     Stein-Säckingen|          -30|13.05.2019 05:30|13.05.2019 05:30|\n",
      "|13.05.2019 05:37:22|13.05.2019|85:11:17215:001|  17215| Zug|   8500322|          Laufenburg|          -38|13.05.2019 05:38|13.05.2019 05:38|\n",
      "|                   |14.05.2019|85:11:17215:001|  17215| Zug|   8500010|           Basel SBB|         null|14.05.2019 04:59|14.05.2019 04:59|\n",
      "|14.05.2019 05:04:23|14.05.2019|85:11:17215:001|  17215| Zug|   8500020|             Muttenz|           83|14.05.2019 05:03|14.05.2019 05:03|\n",
      "|14.05.2019 05:08:02|14.05.2019|85:11:17215:001|  17215| Zug|   8500021|            Pratteln|           62|14.05.2019 05:07|14.05.2019 05:07|\n",
      "|14.05.2019 05:10:13|14.05.2019|85:11:17215:001|  17215| Zug|   8517131|Pratteln Salina R...|           73|14.05.2019 05:09|14.05.2019 05:09|\n",
      "|14.05.2019 05:12:15|14.05.2019|85:11:17215:001|  17215| Zug|   8500300|         Kaiseraugst|           15|14.05.2019 05:12|14.05.2019 05:12|\n",
      "|14.05.2019 05:15:21|14.05.2019|85:11:17215:001|  17215| Zug|   8500313|Rheinfelden Augarten|           21|14.05.2019 05:15|14.05.2019 05:15|\n",
      "|14.05.2019 05:17:33|14.05.2019|85:11:17215:001|  17215| Zug|   8500301|         Rheinfelden|          -27|14.05.2019 05:18|14.05.2019 05:18|\n",
      "|14.05.2019 05:20:51|14.05.2019|85:11:17215:001|  17215| Zug|   8500302|              Möhlin|           -9|14.05.2019 05:21|14.05.2019 05:21|\n",
      "|14.05.2019 05:25:27|14.05.2019|85:11:17215:001|  17215| Zug|   8500303|               Mumpf|           27|14.05.2019 05:25|14.05.2019 05:25|\n",
      "|14.05.2019 05:29:05|14.05.2019|85:11:17215:001|  17215| Zug|   8500320|     Stein-Säckingen|          -55|14.05.2019 05:30|14.05.2019 05:30|\n",
      "|14.05.2019 05:37:29|14.05.2019|85:11:17215:001|  17215| Zug|   8500322|          Laufenburg|          -31|14.05.2019 05:38|14.05.2019 05:38|\n",
      "|                   |15.05.2019|85:11:17215:001|  17215| Zug|   8500010|           Basel SBB|         null|15.05.2019 04:59|15.05.2019 04:59|\n",
      "|15.05.2019 05:03:49|15.05.2019|85:11:17215:001|  17215| Zug|   8500020|             Muttenz|           49|15.05.2019 05:03|15.05.2019 05:03|\n",
      "|15.05.2019 05:09:34|15.05.2019|85:11:17215:001|  17215| Zug|   8500021|            Pratteln|          154|15.05.2019 05:07|15.05.2019 05:07|\n",
      "|15.05.2019 05:11:33|15.05.2019|85:11:17215:001|  17215| Zug|   8517131|Pratteln Salina R...|          153|15.05.2019 05:09|15.05.2019 05:09|\n",
      "|15.05.2019 05:13:40|15.05.2019|85:11:17215:001|  17215| Zug|   8500300|         Kaiseraugst|          100|15.05.2019 05:12|15.05.2019 05:12|\n",
      "|15.05.2019 05:16:35|15.05.2019|85:11:17215:001|  17215| Zug|   8500313|Rheinfelden Augarten|           95|15.05.2019 05:15|15.05.2019 05:15|\n",
      "|15.05.2019 05:18:52|15.05.2019|85:11:17215:001|  17215| Zug|   8500301|         Rheinfelden|           52|15.05.2019 05:18|15.05.2019 05:18|\n",
      "|15.05.2019 05:21:55|15.05.2019|85:11:17215:001|  17215| Zug|   8500302|              Möhlin|           55|15.05.2019 05:21|15.05.2019 05:21|\n",
      "|15.05.2019 05:26:17|15.05.2019|85:11:17215:001|  17215| Zug|   8500303|               Mumpf|           77|15.05.2019 05:25|15.05.2019 05:25|\n",
      "|15.05.2019 05:29:44|15.05.2019|85:11:17215:001|  17215| Zug|   8500320|     Stein-Säckingen|          -16|15.05.2019 05:30|15.05.2019 05:30|\n",
      "|15.05.2019 05:37:31|15.05.2019|85:11:17215:001|  17215| Zug|   8500322|          Laufenburg|          -29|15.05.2019 05:38|15.05.2019 05:38|\n",
      "|                   |16.05.2019|85:11:17215:001|  17215| Zug|   8500010|           Basel SBB|         null|16.05.2019 04:59|16.05.2019 04:59|\n",
      "|16.05.2019 05:04:10|16.05.2019|85:11:17215:001|  17215| Zug|   8500020|             Muttenz|           70|16.05.2019 05:03|16.05.2019 05:03|\n",
      "|16.05.2019 05:07:41|16.05.2019|85:11:17215:001|  17215| Zug|   8500021|            Pratteln|           41|16.05.2019 05:07|16.05.2019 05:07|\n",
      "|16.05.2019 05:09:59|16.05.2019|85:11:17215:001|  17215| Zug|   8517131|Pratteln Salina R...|           59|16.05.2019 05:09|16.05.2019 05:09|\n",
      "|16.05.2019 05:12:10|16.05.2019|85:11:17215:001|  17215| Zug|   8500300|         Kaiseraugst|           10|16.05.2019 05:12|16.05.2019 05:12|\n",
      "|16.05.2019 05:15:09|16.05.2019|85:11:17215:001|  17215| Zug|   8500313|Rheinfelden Augarten|            9|16.05.2019 05:15|16.05.2019 05:15|\n",
      "|16.05.2019 05:17:30|16.05.2019|85:11:17215:001|  17215| Zug|   8500301|         Rheinfelden|          -30|16.05.2019 05:18|16.05.2019 05:18|\n",
      "|16.05.2019 05:21:00|16.05.2019|85:11:17215:001|  17215| Zug|   8500302|              Möhlin|            0|16.05.2019 05:21|16.05.2019 05:21|\n",
      "|16.05.2019 05:25:33|16.05.2019|85:11:17215:001|  17215| Zug|   8500303|               Mumpf|           33|16.05.2019 05:25|16.05.2019 05:25|\n",
      "|16.05.2019 05:28:52|16.05.2019|85:11:17215:001|  17215| Zug|   8500320|     Stein-Säckingen|          -68|16.05.2019 05:30|16.05.2019 05:30|\n",
      "|16.05.2019 05:37:00|16.05.2019|85:11:17215:001|  17215| Zug|   8500322|          Laufenburg|          -60|16.05.2019 05:38|16.05.2019 05:38|\n",
      "+-------------------+----------+---------------+-------+----+----------+--------------------+-------------+----------------+----------------+"
     ]
    }
   ],
   "source": [
    "# Get a simpler dataframe with delays for each trip and without duplicated rows\n",
    "# Solve null values: Remove columns with more than two null-values\n",
    "# and Copy \"Arrival_Time\" value if \"Departure_Time\" is null and viceversa\n",
    "\n",
    "delays_df = (\n",
    "    simple_df \n",
    "    .withColumn('Arrival_null', F.when(F.col('Arrival_Time') == '', None).otherwise(F.col('Arrival_Time')))\n",
    "    .withColumn('Departure_null', F.when(F.col('Departure_Time') == '', None).otherwise(F.col('Departure_Time')))\n",
    "    .drop('Arrival_Time','Departure_Time')\n",
    "    .dropna(thresh=1,subset=('Arrival_null','Departure_null'))\n",
    "    .withColumn(\"Departure\",F.coalesce(F.col('Arrival_null'),F.col('Departure_null')))\\\n",
    "    .withColumn(\"Arrival\", F.coalesce(F.col('Departure_null'),F.col('Arrival_null')))\\\n",
    "    .drop('Arrival_null','Departure_null')\n",
    "    .orderBy('Trip_ID','Day','Arrival','Departure')\n",
    "    \n",
    ")\n",
    "delays_df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove rows corresponding to trips appearing only once on the dataframe\n",
    "# These removable trips actually come from / go to stations outside Zurich\n",
    "ids_counts = simple_df.groupBy('Trip_ID','Day').count()\n",
    "ids_trips = ids_counts.where(ids_counts['count']>1).select('Trip_ID').distinct()\n",
    "df = delays_df.join(ids_trips, \"Trip_ID\").orderBy('Trip_ID','Arrival','Departure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+-------------------+----------+-------+----+----------+----------------+----------------+-----+-------+-----------+----------+\n",
      "|        Trip_ID|        Station_Name|       Arrival_Real|       Day|Line_ID|Type|Station_ID|       Departure|         Arrival|Total|Delayed|Probability|Mean_Delay|\n",
      "+---------------+--------------------+-------------------+----------+-------+----+----------+----------------+----------------+-----+-------+-----------+----------+\n",
      "|85:11:17215:001|           Basel SBB|                   |13.05.2019|  17215| Zug|   8500010|13.05.2019 04:59|13.05.2019 04:59|    4|      0|        0.0|       0.0|\n",
      "|85:11:17215:001|             Muttenz|13.05.2019 05:04:55|13.05.2019|  17215| Zug|   8500020|13.05.2019 05:03|13.05.2019 05:03|    4|      4|        1.0|     79.25|\n",
      "|85:11:17215:001|            Pratteln|13.05.2019 05:08:38|13.05.2019|  17215| Zug|   8500021|13.05.2019 05:07|13.05.2019 05:07|    4|      4|        1.0|     88.75|\n",
      "|85:11:17215:001|Pratteln Salina R...|13.05.2019 05:10:39|13.05.2019|  17215| Zug|   8517131|13.05.2019 05:09|13.05.2019 05:09|    4|      4|        1.0|      96.0|\n",
      "|85:11:17215:001|         Kaiseraugst|13.05.2019 05:12:52|13.05.2019|  17215| Zug|   8500300|13.05.2019 05:12|13.05.2019 05:12|    4|      4|        1.0|     44.25|\n",
      "|85:11:17215:001|Rheinfelden Augarten|13.05.2019 05:15:46|13.05.2019|  17215| Zug|   8500313|13.05.2019 05:15|13.05.2019 05:15|    4|      4|        1.0|     42.75|\n",
      "|85:11:17215:001|         Rheinfelden|13.05.2019 05:18:09|13.05.2019|  17215| Zug|   8500301|13.05.2019 05:18|13.05.2019 05:18|    4|      2|        0.5|      30.5|\n",
      "|85:11:17215:001|              Möhlin|13.05.2019 05:21:17|13.05.2019|  17215| Zug|   8500302|13.05.2019 05:21|13.05.2019 05:21|    4|      2|        0.5|      36.0|\n",
      "|85:11:17215:001|               Mumpf|13.05.2019 05:26:04|13.05.2019|  17215| Zug|   8500303|13.05.2019 05:25|13.05.2019 05:25|    4|      4|        1.0|     50.25|\n",
      "|85:11:17215:001|     Stein-Säckingen|13.05.2019 05:29:30|13.05.2019|  17215| Zug|   8500320|13.05.2019 05:30|13.05.2019 05:30|    4|      0|        0.0|       0.0|\n",
      "|85:11:17215:001|          Laufenburg|13.05.2019 05:37:22|13.05.2019|  17215| Zug|   8500322|13.05.2019 05:38|13.05.2019 05:38|    4|      0|        0.0|       0.0|\n",
      "+---------------+--------------------+-------------------+----------+-------+----+----------+----------------+----------------+-----+-------+-----------+----------+"
     ]
    }
   ],
   "source": [
    "#Compute total number of connections (trip and station)\n",
    "df = delays_df.fillna(0)\n",
    "\n",
    "df_total_trips = df.groupBy('Trip_ID','Station_Name')\\\n",
    "                   .count().toDF('Trip_ID','Station_Name','Total')\n",
    "\n",
    "#Compute number of delayed connections (trip and station)\n",
    "df_delayed_trips = df.where(df['Arrival_Delay']>0).groupBy('Trip_ID','Station_Name')\\\n",
    "                    .count().toDF('Trip_ID','Station_Name','Delayed')\n",
    "\n",
    "#Compute average delay for every connection (trip and station)\n",
    "df_mean_delays = df.where(df['Arrival_Delay']>0).groupBy('Trip_ID','Station_Name')\\\n",
    "                .agg(F.mean('Arrival_Delay').alias(\"Mean_Delay\"))\n",
    "\n",
    "# Join dataframes\n",
    "df_prob = df_total_trips.join(df_delayed_trips, on = ['Trip_ID','Station_Name'],how='left')\\\n",
    "            .withColumn(\"Probability\", F.col(\"Delayed\")/F.col(\"Total\"))\n",
    "\n",
    "df_prob_and_delays = df_prob.join(df_mean_delays, on = ['Trip_ID','Station_Name'],how='left')\n",
    "\n",
    "df_final = df.join(df_prob_and_delays,on =['Trip_ID','Station_Name'],how='left').drop('Arrival_Delay')\\\n",
    "            .orderBy('Trip_ID','Day','Arrival').dropDuplicates(['Station_Name','Trip_ID','Mean_Delay'])\\\n",
    "            .orderBy('Trip_ID','Day','Arrival').fillna(0).cache()\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final dataframe showing delay probabilities for each connection (in a normal workday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Filter data to trips happening only a single working day between 5h and 21h \n",
    "#df_day =df_final.where(F.col('Day')=='15.05.2019') \n",
    "df_min_hour = df_final.where(F.hour(F.unix_timestamp(F.col('Arrival'), \"dd.MM.yyyy HH:mm\").cast('timestamp'))>=5) \n",
    "df_max_hour = df_min_hour.where(F.hour(F.unix_timestamp(F.col('Departure'), \"dd.MM.yyyy HH:mm\").cast('timestamp'))<=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rank stops by departure_time for every trip and day \n",
    "from pyspark.sql import Window\n",
    "trip_window = Window.partitionBy('Trip_ID','Day').orderBy(F.asc('Departure'))\n",
    "trip_rank = F.rank().over(trip_window).alias('stop')\n",
    "begin = df_max_hour.select('*', trip_rank).alias('begin').orderBy('Trip_ID','Arrival','Departure').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+-------------------+----------+-------+----+----------+----------------+----------------+-----+-------+-----------+----------+----+\n",
      "|        Trip_ID|        Station_Name|       Arrival_Real|       Day|Line_ID|Type|Station_ID|       Departure|         Arrival|Total|Delayed|Probability|Mean_Delay|stop|\n",
      "+---------------+--------------------+-------------------+----------+-------+----+----------+----------------+----------------+-----+-------+-----------+----------+----+\n",
      "|85:11:17215:001|             Muttenz|13.05.2019 05:04:55|13.05.2019|  17215| Zug|   8500020|13.05.2019 05:03|13.05.2019 05:03|    4|      4|        1.0|     79.25|   1|\n",
      "|85:11:17215:001|            Pratteln|13.05.2019 05:08:38|13.05.2019|  17215| Zug|   8500021|13.05.2019 05:07|13.05.2019 05:07|    4|      4|        1.0|     88.75|   2|\n",
      "|85:11:17215:001|Pratteln Salina R...|13.05.2019 05:10:39|13.05.2019|  17215| Zug|   8517131|13.05.2019 05:09|13.05.2019 05:09|    4|      4|        1.0|      96.0|   3|\n",
      "|85:11:17215:001|         Kaiseraugst|13.05.2019 05:12:52|13.05.2019|  17215| Zug|   8500300|13.05.2019 05:12|13.05.2019 05:12|    4|      4|        1.0|     44.25|   4|\n",
      "|85:11:17215:001|Rheinfelden Augarten|13.05.2019 05:15:46|13.05.2019|  17215| Zug|   8500313|13.05.2019 05:15|13.05.2019 05:15|    4|      4|        1.0|     42.75|   5|\n",
      "|85:11:17215:001|         Rheinfelden|13.05.2019 05:18:09|13.05.2019|  17215| Zug|   8500301|13.05.2019 05:18|13.05.2019 05:18|    4|      2|        0.5|      30.5|   6|\n",
      "|85:11:17215:001|              Möhlin|13.05.2019 05:21:17|13.05.2019|  17215| Zug|   8500302|13.05.2019 05:21|13.05.2019 05:21|    4|      2|        0.5|      36.0|   7|\n",
      "|85:11:17215:001|               Mumpf|13.05.2019 05:26:04|13.05.2019|  17215| Zug|   8500303|13.05.2019 05:25|13.05.2019 05:25|    4|      4|        1.0|     50.25|   8|\n",
      "|85:11:17215:001|     Stein-Säckingen|13.05.2019 05:29:30|13.05.2019|  17215| Zug|   8500320|13.05.2019 05:30|13.05.2019 05:30|    4|      0|        0.0|       0.0|   9|\n",
      "|85:11:17215:001|          Laufenburg|13.05.2019 05:37:22|13.05.2019|  17215| Zug|   8500322|13.05.2019 05:38|13.05.2019 05:38|    4|      0|        0.0|       0.0|  10|\n",
      "+---------------+--------------------+-------------------+----------+-------+----+----------+----------------+----------------+-----+-------+-----------+----------+----+"
     ]
    }
   ],
   "source": [
    "begin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create dataframe for every connection \n",
    "end = begin.drop('Departure').withColumn('stop', begin.stop -1).alias('end')\n",
    "data = begin.drop('Arrival','Mean_Delay','Probability').join(end, on=['stop','Day','Trip_ID','Type','Line_ID'])\\\n",
    "            .orderBy('Trip_ID','Arrival','Departure').drop('stop')\\\n",
    "            .toDF('Day','Trip_ID','Type','Line_ID','Start_Station','Start_ID','Start_Time',\n",
    "                  'Stop_Station','Stop_ID','Stop_Time','Propability','Mean_Delay')\\\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Line_ID: string (nullable = true)\n",
      " |-- Start_Station: string (nullable = true)\n",
      " |-- Start_ID: string (nullable = true)\n",
      " |-- Start_Time: string (nullable = true)\n",
      " |-- Stop_Station: string (nullable = true)\n",
      " |-- Stop_ID: string (nullable = true)\n",
      " |-- Stop_Time: string (nullable = true)\n",
      " |-- Propability: double (nullable = false)\n",
      " |-- Mean_Delay: double (nullable = false)"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final dataframe in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o df_stations -n -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "data.to_csv(\"../data/Zurich_TransportConnections_WORKINGDAY.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use stop-times table (for what?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trips_df = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/trips\")\n",
    "#calendar_df = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/calendar\")\n",
    "#routes_df = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/routes\")\n",
    "stop_times_df = spark.read.orc(\"hdfs:///data/sbb/timetables/orc/stop_times\")\n",
    "stop_times_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_times = stop_times_df.join(ids,stop_times_df['stop_id']==ids['_c0'])\\\n",
    "                .select(\"stop_sequence\",\"stop_id\",\"arrival_time\",\"departure_time\")\\\n",
    "                .orderBy('stop_id','arrival_time','departure_time','stop_sequence').dropDuplicates()\n",
    "relevant_times.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
